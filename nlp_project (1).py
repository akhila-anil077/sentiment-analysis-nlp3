# -*- coding: utf-8 -*-
"""NLP_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qujIy6K9YlHwFGcqHyCZWKxRvFfffzMg

Dataset
https://www.kaggle.com/datasets/yasserh/amazon-product-reviews-dataset
"""

# 1. Load Data
import pandas as pd

# Load the Amazon Fine Food Reviews dataset
df = pd.read_csv("amazon_product_review.csv")
df.head()

print(df.columns)

df = df[['reviews.text', 'reviews.rating']].dropna()
df.columns = ['Text', 'Score']

"""Preprocess: Tokenize, Lemmatize, Remove Stopwords"""

import re
import string
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# Download resources
nltk.download('stopwords')
nltk.download('wordnet')

stop_words = set(stopwords.words('english'))
negations = {'no', 'not', 'never', "n't"}
lemmatizer = WordNetLemmatizer()

def clean_text(text):
    text = str(text).lower()
    text = re.sub(r"http\S+|www\S+", '', text)  # remove links
    text = text.translate(str.maketrans('', '', string.punctuation))  # remove punctuation
    tokens = text.split()
    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]
    return " ".join(tokens)

df['Cleaned_Text'] = df['Text'].apply(clean_text)
df['Cleaned_Text'].head()

"""Convert Text to TF-IDF Vectors"""

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))
X = vectorizer.fit_transform(df['Cleaned_Text'])

# Converting score to sentiment label
def score_to_sentiment(score):
    if score <= 2:
        return 'negative'
    elif score == 3:
        return 'neutral'
    else:
        return 'positive'

df['Sentiment'] = df['Score'].apply(score_to_sentiment)
y = df['Sentiment']

"""Train and Test Split"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

"""Model Training (Logistic Regression)"""

from sklearn.linear_model import LogisticRegression

model = LogisticRegression(max_iter=1000, class_weight='balanced')
model.fit(X_train, y_train)

"""Evaluation"""

from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns

y_pred = model.predict(X_test)
le = LabelEncoder()
le.fit(df['Sentiment'].unique())

cm = confusion_matrix(y_test, y_pred, labels=le.classes_)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

print(classification_report(y_test, y_pred, target_names=le.classes_))

"""Visualization"""

# WordCloud Visualization
from wordcloud import WordCloud

def plot_wordcloud(sentiment_label):
    text = " ".join(df[df['Sentiment'] == sentiment_label]['Cleaned_Text'])
    wc = WordCloud(width=800, height=400, background_color='white').generate(text)
    plt.figure(figsize=(10, 5))
    plt.imshow(wc, interpolation='bilinear')
    plt.axis('off')
    plt.title(f"WordCloud for {sentiment_label} Reviews")
    plt.show()

plot_wordcloud('positive')
plot_wordcloud('negative')
plot_wordcloud('neutral')

# Save Model
import joblib

joblib.dump(model, 'model.pkl')
joblib.dump(vectorizer, 'tfidf.pkl')
joblib.dump(le, 'label_encoder.pkl')